# gRPC
GRPC_HOST=0.0.0.0
GRPC_PORT=50051

# FastAPI (internal-only health endpoint)
HTTP_ENABLE=true
HTTP_HOST=127.0.0.1
HTTP_PORT=8000

# Database (async SQLAlchemy URL)
DATABASE_URL=postgresql+asyncpg://devuser:devpassword@localhost:5432/scrapper-dev

# MinIO
MINIO_ENDPOINT=localhost:9000
# Local dev defaults (matches docker-compose.yml). Change for production.
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=minioadmin
MINIO_BUCKET=scraped-documents
MINIO_SECURE=false

# Scraping constraints
SCRAPE_TIMEOUT_MS=30000
SCRAPE_USER_AGENT=WebScraperService/0.1.0
MAX_TOTAL_DOCUMENTS_PER_JOB=5000
SCRAPE_MAX_RETRIES=2
SCRAPE_RETRY_BACKOFF_MS=500
MAX_DOCUMENT_BYTES=26214400
MAX_IMAGES_PER_DOCUMENT=50
MAX_IMAGE_BYTES=5242880
MIN_WORD_COUNT=100
MIN_TEXT_TO_HTML_RATIO=0.05
DISCOVERY_MIN_WORD_COUNT=10
DISCOVERY_MIN_TEXT_TO_HTML_RATIO=0.0

# Optional rate limiting
ENABLE_RATE_LIMITING=false
RATE_LIMIT_PER_DOMAIN_RPS=2.0

# Politeness: robots.txt
RESPECT_ROBOTS_TXT=true
ROBOTS_CACHE_TTL_SECONDS=3600
ROBOTS_TIMEOUT_SECONDS=10

# Phase 2 & Phase 3 (LLM providers)
# LLM Provider: "ollama" or "openai"
LLM_PROVIDER=ollama

# Ollama config (for local LLM)
OLLAMA_HOST=localhost
OLLAMA_PORT=11434
OLLAMA_DEFAULT_MODEL=qwen2.5:3b

# OpenAI config (for GPT-4o, GPT-4, etc.)
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your-api-key-here
# Optional: For OpenAI-compatible APIs (e.g., Azure OpenAI, local proxies)
# OPENAI_BASE_URL=https://api.openai.com/v1
# OPENAI_DEFAULT_MODEL=gpt-4o

# Phase 3 BrowserUse integration (optional)
# "heuristic" (default) or "browser_use"
PHASE3_AGENT_BACKEND=heuristic
BROWSER_USE_SERVICE_BASE_URL=http://localhost:9010
# Optional shared secret for BrowserUse service
BROWSER_USE_INTERNAL_API_KEY=
BROWSER_USE_TIMEOUT_SECONDS=600
BROWSER_USE_MAX_STEPS=60
BROWSER_USE_TEMPERATURE=0.2
BROWSER_USE_HEADLESS=true

# Discovery caps
DISCOVERY_MAX_DEPTH_CAP=5
# CYON "all docs" is ~600 pages; keep cap high enough for full discovery by default.
DISCOVERY_MAX_PAGES_CAP=2000
LLM_TEMPERATURE_DEFAULT=0.1
LLM_MAX_TOKENS_CAP=4096
LLM_TIMEOUT_SECONDS_CAP=120

# Logging
LOG_LEVEL=INFO


